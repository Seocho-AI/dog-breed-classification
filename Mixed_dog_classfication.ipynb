{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687fd1b5-8abd-49ca-b9f9-a44e7b69f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 554ms/step\n",
      "Feature maps shape:  (1, 2048)\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "Feature maps shape:  (1, 2048)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Feature maps shape:  (1, 4032)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Feature maps shape:  (1, 1536)\n",
      "Final feature maps shape (1, 9664)\n",
      "Predicted label: toy_poodle\n",
      "Probability of prediction): 100 %\n",
      "tensor([[9.9036e-01, 6.8113e-03, 6.2964e-04, 4.7763e-04, 3.0030e-04, 1.6055e-04,\n",
      "         1.5749e-04, 1.1635e-04, 7.0684e-05, 4.4619e-05, 4.0008e-05, 3.8993e-05,\n",
      "         3.5659e-05, 3.4508e-05, 3.1929e-05, 2.9077e-05, 2.8828e-05, 2.6643e-05,\n",
      "         2.6293e-05, 2.5781e-05, 2.2832e-05, 2.2253e-05, 2.2142e-05, 1.8306e-05,\n",
      "         1.6396e-05, 1.5855e-05, 1.5797e-05, 1.5763e-05, 1.4359e-05, 1.2708e-05,\n",
      "         1.2250e-05, 1.2195e-05, 1.1920e-05, 1.1881e-05, 1.1780e-05, 1.1773e-05,\n",
      "         1.1010e-05, 1.0798e-05, 8.5260e-06, 8.0388e-06, 7.9664e-06, 7.9654e-06,\n",
      "         7.9622e-06, 7.3816e-06, 7.1343e-06, 6.9335e-06, 6.3644e-06, 6.3589e-06,\n",
      "         6.1608e-06, 6.1492e-06, 5.6968e-06, 5.5442e-06, 5.4007e-06, 5.1722e-06,\n",
      "         5.1426e-06, 5.1403e-06, 5.0755e-06, 4.9568e-06, 4.7866e-06, 4.7779e-06,\n",
      "         4.7187e-06, 4.6988e-06, 4.6586e-06, 4.5574e-06, 4.3973e-06, 4.2133e-06,\n",
      "         4.1177e-06, 3.8930e-06, 3.8090e-06, 3.7073e-06, 3.6627e-06, 3.5557e-06,\n",
      "         3.5024e-06, 3.4551e-06, 3.2072e-06, 3.1919e-06, 3.1801e-06, 3.1648e-06,\n",
      "         3.1290e-06, 3.1085e-06, 3.0004e-06, 2.9430e-06, 2.6899e-06, 2.5142e-06,\n",
      "         2.5068e-06, 2.1885e-06, 2.0957e-06, 2.0893e-06, 2.0172e-06, 1.9574e-06,\n",
      "         1.8926e-06, 1.7941e-06, 1.7276e-06, 1.7083e-06, 1.6689e-06, 1.6197e-06,\n",
      "         1.5920e-06, 1.5750e-06, 1.5710e-06, 1.5552e-06, 1.5483e-06, 1.5130e-06,\n",
      "         1.4779e-06, 1.4679e-06, 1.4624e-06, 1.4555e-06, 1.4116e-06, 1.3658e-06,\n",
      "         1.3229e-06, 1.2709e-06, 1.2350e-06, 1.2342e-06, 1.2123e-06, 1.1531e-06,\n",
      "         9.8215e-07, 8.2668e-07, 7.9816e-07, 7.7137e-07, 7.3448e-07, 3.5057e-07]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np #\n",
    "import pandas as pd\n",
    "\n",
    "# from keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "import torch\n",
    "\n",
    "def get_features(model_name, model_preprocessor, input_size, data):\n",
    "\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                            input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    \n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps\n",
    "\n",
    "def extact_features(data):\n",
    "    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n",
    "    xception_features = get_features(Xception, xception_preprocessor, img_size, data)\n",
    "    nasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, data)\n",
    "    inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n",
    "\n",
    "    final_features = np.concatenate([inception_features,\n",
    "                                     xception_features,\n",
    "                                     nasnet_features,\n",
    "                                     inc_resnet_features],axis=-1)\n",
    "\n",
    "    print('Final feature maps shape', final_features.shape)\n",
    "\n",
    "    #deleting to free up ram memory\n",
    "    del inception_features \n",
    "    del xception_features\n",
    "    del nasnet_features\n",
    "    del inc_resnet_features\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    return final_features\n",
    "\n",
    "img_size = (331,331,3)\n",
    "\n",
    "inception_preprocessor = preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "nasnet_preprocessor = preprocess_input\n",
    "\n",
    "loaded_model_tf = tf.keras.models.load_model('classification_model.h5')\n",
    "labels = pd.read_csv('labels.csv')\n",
    "classes = sorted(list(set(labels['breed'])))\n",
    "\n",
    "img_g = load_img('dataset/[경기-수원-2022-00328].jpg',target_size = img_size)\n",
    "img_g = np.expand_dims(img_g, axis=0) # as we trained our model in (row, img_height, img_width, img_rgb) format, np.expand_dims convert the image into this format\n",
    "# img_g\n",
    "# #Predict test labels given test data features.\n",
    "test_features = extact_features(img_g)\n",
    "predg = loaded_model_tf.predict(test_features)\n",
    "print(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\n",
    "print(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")\n",
    "\n",
    "tensor=torch.tensor(predg)\n",
    "\n",
    "val, idx = torch.sort(tensor,  descending=True)\n",
    "# 값 top2 값 매핑\n",
    "print(val)\n",
    "\n",
    "# 값 true인 index 찍어보면 견종 나옴\n",
    "print((tensor>0.1).squeeze())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02effe5b-c1b3-4b48-b09f-49b3d54ca6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor>0.1).squeeze()[110]\n",
    "#(tensor>0.001).squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad3672-8c0f-4f24-bbf9-afa68f5b746c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy_poodle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968c999-4fa8-4174-865d-7ae315ee7080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
